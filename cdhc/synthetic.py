import pickle
import matplotlib.pyplot as plt
import operator
import random
import os
import re
import itertools
from collections import defaultdict

from scipy.stats import dirichlet
import numpy as np
import pandas as pd
import pydot

from pycausal import prior as p
from pycausal import search as s
from pycausal.pycausal import pycausal as _pc

from config import TETRAD_ON, METHOD_ON
from method import Method
from data_generation import generate_data

from util import f1, precision, recall, prec_rec_f1, _dot_list_parse

def run_tetrad(algo='gfci', x=None, prior=None, pc=None):
    tetrad = s.tetradrunner()
    tetrad.run(algoId = algo, dfs=x, scoreId = 'sem-bic', dataType = 'continuous',
            maxDegree = -1, faithfulnessAssumed = True, verbose = False, priorKnowledge=prior)
    nodes = tetrad.getNodes()
    edges = tetrad.getEdges()
    graph = tetrad.getTetradGraph()
    dot_str = pc.tetradGraphToDot(graph)
    return dot_str

def compare(N=5000, D=10, M=1, num_conf=5, confounded_sets=None, stored=False, pc=None, algo='gfci'):
    from config import RESULTS_DIR
    for alpha in 2**np.linspace(0, 3, 4):
        path = os.path.join(RESULTS_DIR, f'synthetic/alpha={alpha}')
        os.makedirs(path, exist_ok=True)

        if not confounded_sets:
            confounded_sets = [range(num_conf)]
        else:
            num_conf = [len(x) for x in confounded_sets]
        for i in range(1):
            # The data can be pre-generated by the data-generation process
            # if access to it is somehow important. If this has been done,
            # it can be loaded from the relevant files
            if stored:
                from config import RESULTS_DIR
                x = pd.read_csv(os.path.join(path, f'x{i}.csv'))
                z = pd.read_csv(os.path.join(path, f'z{i}.csv'))
                with open(os.path.join(path, f'g{i}.csv'), 'rb') as g_file:
                    G_true = pickle.load(g_file)
                with open(os.path.join(path, f'conf{i}.csv'), 'rb') as conf_file:
                    confounded_sets = pickle.load(conf_file)
            # Otherwise we just generate the data here on the fly
            else:
                x, z, G_true, confounded_set = generate_data(N, D, M, confounded_sets, [alpha], 1)
            # TETRAD and METHOD can be run separately because you might, say want to run them
            # on different machines
            # This runs GFCI from the TETRAD package
            if TETRAD_ON:
                print('Running TETRAD')
                t_path = os.path.join(path, f'{algo}_conf-{N}-{D}-{M}-{num_conf}[{i}]')
                dot_path = os.path.join(path, f'{algo}_dot-{N}-{D}-{M}-{num_conf}[{i}]')
                # Only run if we haven't run before
                if not os.path.isfile(t_path):
                    dot_str = run_tetrad(algo=algo, x=x, pc=pc)
                    dot_list = dot_str.lstrip('[\'digraph g {\n').rstrip('; \n\'}').split('; \n ')
                    _, maybe_conf, def_conf = _dot_list_parse(dot_list)
                    print(dot_path, t_path, sep='\n')
                    with open(dot_path, 'wb') as dot_file:
                        pickle.dump({'G_true': G_true, 'dot': dot_str}, dot_file)
                    with open(t_path, 'wb') as tetrad_file:
                        pickle.dump((maybe_conf, def_conf), tetrad_file)
            # This runs our method
            if METHOD_ON:
                m_path = os.path.join(path, f'm_conf-{N}-{D}-{M}-{num_conf}[{i}]')
                # Only run if we haven't run before
                if not os.path.isfile(m_path):
                    x.columns = map(int, x.columns)
                    m = Method(x, G_true=G_true)
                    m.iterative_fit()
                    with open(m_path, 'wb') as m_file:
                        pickle.dump(m, m_file)

def eval_D(pc=None, algo='gfci'):
    M = 1
    num_confs = {10: 3, 25:5, 50: 5}
    for D in [10, 25, 50]:
        num_conf = num_confs[D]
        compare(D=D, M=M, num_conf=num_conf, pc=pc, algo=algo)

def main():
    random.seed(1)
    np.random.seed(1)
    # We need to start and stop the JVM only if we care to run TETRAD in the first place
    if TETRAD_ON:
        pc = _pc()
        pc.start_vm()
    else:
        pc = None

    eval_D(pc=pc, algo='rfci')

    if TETRAD_ON:
        pc.stop_vm()

if __name__ == '__main__':
    main()

